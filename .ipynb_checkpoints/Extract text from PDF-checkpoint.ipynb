{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import PyPDF2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_1 = open('/home/ro/Knygos/Scientific American 1993-2012/2012/SciAm - 2012.05 - A Unified Physics.pdf', 'rb')\n",
    "k1 = PyPDF2.PdfFileReader(k_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1.getNumPages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discerning the number of pages will allow us to \n",
    "#parse through all the pages\n",
    "\n",
    "num_pages = k1.numPages\n",
    "count = 0\n",
    "text = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#While loop will read  each page\n",
    "\n",
    "while count < num_pages:\n",
    "    pageObj = k1.getPage(count)\n",
    "    count += 1\n",
    "    text += pageObj.extractText().lower()\n",
    "\n",
    "#This if statement exists to check if the above library returned \n",
    "#words. It's done because PyPDF2 cannot read scanned files.\n",
    "\n",
    "# if text != '':\n",
    "#     text = text\n",
    "\n",
    "#If the above returns as False, we run the OCR library textract to \n",
    "#convert scanned/image based PDF files into text\n",
    "\n",
    "# else:\n",
    "#     text = textract.process(fileurl, method='tesseract', language='eng')\n",
    "\n",
    "# Now we have a text variable which contains all the text derived \n",
    "#from our PDF file. Type print(text) to see what it contains. It \n",
    "#likely contains a lot of spaces, possibly junk such as '\\n' etc.\n",
    "\n",
    "# Now, we will clean our text variable, and return it as a list of keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272661"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_tokenize` function to properly tokenize this text, compare to the whitespace splitting we used above:\n",
    "ls_lower = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47759"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ls_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['may', '2012', 'your', 'future', 'health', 'Â©', '2012', 'scientific']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_lower[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_words = nltk.corpus.stopwords.words('english') + list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "#check useless words and how much are of these\n",
    "print(len(nltk.corpus.stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering words from list\n",
    "filtered_words = [word for word in ls_lower if not word in useless_words and word.isalpha() and len(word) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22147"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "calc_words = Counter(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('american', 166),\n",
       " ('may', 132),\n",
       " ('one', 128),\n",
       " ('new', 112),\n",
       " ('scientific', 104),\n",
       " ('could', 81),\n",
       " ('university', 76),\n",
       " ('would', 74),\n",
       " ('science', 70),\n",
       " ('two', 66)]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common = calc_words.most_common()\n",
    "most_common[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_frame = pd.DataFrame(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7274"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_frame.to_csv('A Unified Physics.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
